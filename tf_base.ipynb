{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212d3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df92a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个随机数（标量）\n",
    "random_float = tf.random.uniform(shape=())\n",
    "\n",
    "#定义一个有两个元素的零向量\n",
    "zero_vector = tf.zeros(shape=(2))\n",
    "\n",
    "#定义两个2×2的常量举证\n",
    "A = tf.constant([[1.,2.],[3.,4.]])\n",
    "B = tf.constant([[5.,6.],[7.,8.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7afd498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<dtype: 'float32'>\n",
      "<bound method _EagerTensorBase.numpy of <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>>\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(A.dtype)\n",
    "print(A.numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c7f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 6.  8.]\n",
      " [10. 12.]], shape=(2, 2), dtype=float32) tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "C = tf.add(A,B)\n",
    "D = tf.matmul(A,B)\n",
    "print(C,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92338482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#计算函数 y(x) = x^2 在 x = 3 时的导数：\n",
    "x = tf.Variable(initial_value=3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.square(x)\n",
    "y_grad = tape.gradient(y,x)\n",
    "print(y)\n",
    "print(y_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e067c5",
   "metadata": {},
   "source": [
    "这里 x 是一个初始化为 3 的 变量 （Variable），使用 tf.Variable() 声明。与普通张量一样，变量同样具有形状、类型和值三种属性。使用变量需要有一个初始化过程，可以通过在 tf.Variable() 中指定 initial_value 参数来指定初始值。这里将变量 x 初始化为 3. 1。变量与普通张量的一个重要区别是其默认能够被 TensorFlow 的自动求导机制所求导，因此往往被用于定义机器学习模型的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f32a9",
   "metadata": {},
   "source": [
    "tf.GradientTape() 是一个自动求导的记录器。只要进入了 with tf.GradientTape() as tape 的上下文环境，则在该环境中计算步骤都会被自动记录。比如在上面的示例中，计算步骤 y = tf.square(x) 即被自动记录。离开上下文环境后，记录将停止，但记录器 tape 依然可用，因此可以通过 y_grad = tape.gradient(y, x) 求张量 y 对变量 x 的导数。\n",
    "\n",
    "在机器学习中，更加常见的是对多元函数求偏导数，以及对向量或矩阵的求导。这些对于 TensorFlow 也不在话下。以下代码展示了如何使用 tf.GradientTape() 计算函数 L(w, b) = \\|Xw + b - y\\|^2 在 w = (1, 2)^T, b = 1 时分别对 w, b 的偏导数。其中 X = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix},  y = \\begin{bmatrix} 1 \\\\ 2\\end{bmatrix}。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0dcb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
